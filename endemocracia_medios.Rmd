---
title: "Monitoreo de Medios"
output: 
  flexdashboard::flex_dashboard:
    orientation: rows
    vertical_layout: fill
    theme: lumen
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
library(flexdashboard)
```

```{r}
rm(list=ls())
library(tm)
library(wordcloud2)
library(readxl)
library(dplyr)
library(stringr)
library(lubridate)
library(rtweet)
library(DT)
nube<-function(aux,palabras){
  docs<-Corpus(VectorSource(aux))
  docs <- docs %>%
    tm_map(removeNumbers) %>%
    tm_map(removePunctuation) %>%
    tm_map(stripWhitespace)
  docs <- tm_map(docs, content_transformer(tolower))
  docs <- tm_map(docs, removeWords, stopwords("sp"))
  docs <- tm_map(docs, removeWords, palabras)
  dtm <- TermDocumentMatrix(docs) 
  matrix <- as.matrix(dtm) 
  words <- sort(rowSums(matrix),decreasing=TRUE) 
  df <- data.frame(word = names(words),freq=words)    
  return(df)
}
load("C:\\Users\\Alvaro Chirino\\Documents\\GitHub\\endemocracia_redes\\data\\medios.RData")

tw_hoy<-bd_medios %>% filter(as_date(created_at)==today())
tw_pon<-tw_hoy %>% mutate(nn=1) %>% group_by(screen_name) %>% mutate(nn=cumsum(nn)) %>% filter(nn<=10)
```


# Tendencia en redes ``r today()``

Row
-----------------------------------------------------------------------

### Número de medios

```{r}
valueBox(length(unique(tw_hoy$user_id)), icon = "fa-pencil")
```

### Publicaciones analizadas

```{r}
valueBox(nrow(tw_hoy), icon = "fa-comments")
```

### Publicaciones ponderadas

```{r}
valueBox(nrow(tw_pon), icon = "fa-trash")
```

Row
-----------------------------------------------------------------------

### Publicaciones globales

```{r}
df1<-nube(tw_hoy$text,c("bolivia",tw_medios$screen_name,"btvinforma"))
w1<-wordcloud2(data=df1,color='random-dark',size=0.5,shape = 'pentagon')
w1
```

### Publicaciones Ponderadas

```{r}
#controlando el peso de máximo 10 noticias por medio
df2<-nube(tw_pon %>%  select(text),c("bolivia",tw_medios$screen_name))
w2<-wordcloud2(data=df2,color='random-dark',size=0.5,shape = 'pentagon')
w2
```


# Análisis de Redes

```{r}
library(tm)
library(igraph)
# Build corpus
corpus<-tw_pon$text
corpus <- Corpus(VectorSource(corpus))

# Clean text
corpus <- tm_map(corpus, tolower)
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeNumbers)
cleanset <- tm_map(corpus, removeWords, stopwords('spanish'))
removeURL <- function(x) gsub('http[[:alnum:]]*', '', x)
cleanset <- tm_map(cleanset, content_transformer(removeURL))
cleanset <- tm_map(cleanset, removeWords, c('aapl', 'apple'))
cleanset <- tm_map(cleanset, gsub, 
                   pattern = 'stocks', 
                   replacement = 'stock')
cleanset <- tm_map(cleanset, stripWhitespace)

# Term document matrix
tdm <- TermDocumentMatrix(cleanset)
tdm <- as.matrix(tdm)
tdm <- tdm[rowSums(tdm)>2,]

# Network of terms
tdm[tdm>1] <- 1
termM <- tdm %*% t(tdm)
g <- graph.adjacency(termM, weighted = T, mode = 'undirected')
g <- simplify(g)
V(g)$label <- V(g)$name
V(g)$degree <- degree(g)

# Community detection
prop <- cluster_label_prop(g)

plot(prop, g,vertex.size = V(g)$degree*.5)
```


# Lista de publicaciones

```{r}
DT::datatable(tw_hoy[,c(3,4,5)],style = "bootstrap")
```

# Lista de medios

```{r}
DT::datatable(tw_medios[,c(2,3)],style = "bootstrap")
```
